{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bba5b1e",
   "metadata": {},
   "source": [
    "- 0 : 교내 활동/생활\n",
    "- 1 : 교육과정/과목/수업\n",
    "- 2 : 기숙사\n",
    "- 3 : 수강신청/정정\n",
    "- 4 : 학사 문의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd4ca178",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-31T12:40:42.429963Z",
     "start_time": "2022-03-31T12:40:25.459434Z"
    }
   },
   "outputs": [],
   "source": [
    "## 처음 import 하는 코드\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, Conv1D, GlobalMaxPool1D, concatenate\n",
    "from hanspell import spell_checker\n",
    "from konlpy.tag import Komoran\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from konlpy.tag import Komoran\n",
    "import re\n",
    "import sys\n",
    "import random\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(action='ignore')\n",
    "\n",
    "m = re.compile(\"^N\")\n",
    "n = re.compile(\"^V\")\n",
    "o = re.compile(\"^X\")\n",
    "\n",
    "class Preprocess:\n",
    "    def __init__(self, userdic = None):\n",
    "        self.komoran = Komoran(userdic=userdic)\n",
    "        self.exclusion_tags = [\n",
    "            'JKS','JKC', 'JKG', 'JKB', 'JKV', 'JKQ', 'JX', 'JC', 'SF', 'SP', 'SS', 'SE', 'SO', 'EP', 'EF', 'EC', 'ETN', 'ETM', 'XSN', 'XSV', 'XSA'\n",
    "            ]\n",
    "        \n",
    "    def pos(self, sentence):\n",
    "        return self.komoran.pos(sentence)\n",
    "    \n",
    "    def get_keywords(self, pos, without_tag = False):\n",
    "        f = lambda x : x in self.exclusion_tags\n",
    "        word_list = []\n",
    "        for p in pos:\n",
    "            if f(p[1]) is False:\n",
    "                word_list.append(p if without_tag is False else p[0])\n",
    "        return word_list\n",
    "\n",
    "\n",
    "# 코사인 유사도 계산\n",
    "def cos_sim(vec1, vec2):\n",
    "    return dot(vec1, vec2) / (norm(vec1)*norm(vec2))\n",
    "\n",
    "# TDM 만들기\n",
    "def make_term_doc_mat(sentence_bow, word_dics):\n",
    "    freq_mat={}\n",
    "    \n",
    "    for word in word_dics:\n",
    "        freq_mat[word] = 0\n",
    "        \n",
    "    for word in word_dics:\n",
    "        if word in sentence_bow:\n",
    "            freq_mat[word] += 1\n",
    "            \n",
    "    return freq_mat\n",
    "\n",
    "# 단어 벡터 만들기\n",
    "def make_vector(tdm):\n",
    "    vec = []\n",
    "    for key in tdm:\n",
    "        vec.append(tdm[key])\n",
    "    return vec\n",
    "\n",
    "data = pd.read_excel('./data_for_chat.xlsx')\n",
    "data.fillna('',inplace=True)\n",
    "\n",
    "p = Preprocess(userdic='./user_dic.tsv')\n",
    "# 모델 로드\n",
    "model = load_model('cnn_new_model.h5')\n",
    "model2 = load_model('cnn_new_label2_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58fe8d51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-31T12:40:51.485377Z",
     "start_time": "2022-03-31T12:40:50.421801Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "남제관\n",
      "의도 예측 클래스 :  [2]\n",
      "의도 예측2 클래스 :  [2]\n",
      "['남제관']\n",
      "['남제관', '남제관']\n",
      "73 1.0\n",
      "남제관\n",
      "http://dorm.ajou.ac.kr/dorm/sketch/sketch03_01.jsp\n"
     ]
    }
   ],
   "source": [
    "## 메인 코드\n",
    "\n",
    "# 두번째 label를 위한 사전화\n",
    "start = 11455\n",
    "end = 12580\n",
    "\n",
    "chat_input2 = '남제관'\n",
    "# chat_input2 = spell_checker.check(chat_input).checked\n",
    "print(chat_input2)\n",
    "\n",
    "# 알바\n",
    "alba = ['최신 알바','아주대 알바','근처 알바']\n",
    "if any(format in chat_input2 for format in alba):\n",
    "    execfile(\"./money.py\")\n",
    "    sys.exit()\n",
    "\n",
    "# 오늘 공지\n",
    "notice = ['오늘 공지','최근 공지사항','최근 공지','최신 공지','오늘 공지']\n",
    "if any(format in chat_input2 for format in notice):\n",
    "    execfile(\"./notice_latest.py\")\n",
    "    sys.exit()\n",
    "    \n",
    "# 그저께 공지\n",
    "notice = ['그저께 공지사항','그저께 공지','이틀 전 공지사항','이틀전 공지','2일전 공지사항']\n",
    "if any(format in chat_input2 for format in notice):\n",
    "    execfile(\"./notice_2day.py\")\n",
    "    sys.exit()\n",
    "    \n",
    "# 어제 공지\n",
    "notice = ['어제 공지','어제 공지사항']\n",
    "if any(format in chat_input2 for format in notice):\n",
    "    execfile(\"./notice_yesterday.py\")\n",
    "    sys.exit()\n",
    "\n",
    "# 안녕\n",
    "number = random.randrange(1,4)\n",
    "Hi = ['안녕','안늉','안뇽','ㅎㅇ','방가','반가워','하이루']\n",
    "if any(format in chat_input2 for format in Hi ): \n",
    "    if number == 1:\n",
    "        print(\"ㅎㅇ\")\n",
    "    elif number == 2:\n",
    "        print(\"하이루\")\n",
    "    elif number == 3:\n",
    "        print(\"방가방가\")\n",
    "    elif number == 4:\n",
    "        print(\"안녕\")\n",
    "    sys.exit()\n",
    "\n",
    "# 잘가\n",
    "Bye = ['ㅂㅇ','잘가','빠이','바이','안녕히','ㅃㅇ']\n",
    "number = random.randrange(1,4)\n",
    "if any(format in chat_input2 for format in Bye ):\n",
    "    if number == 1:\n",
    "        print(\"ㅂㅇ\")\n",
    "    elif number == 2:\n",
    "        print(\"잘가\")\n",
    "    elif number == 3:\n",
    "        print(\"ㅇㅋㅇㅋ 빠이!\")\n",
    "    elif number == 4:\n",
    "        print(\"빠이\")\n",
    "    sys.exit()\n",
    "\n",
    "# 고마워\n",
    "Thx = ['땡큐','ㄳ','ㄱㅅ','고마','고맙','ㄸㅋ','땡삼']  \n",
    "number = random.randrange(1,4)\n",
    "if any(format in chat_input2 for format in Thx ) :\n",
    "    if number == 1:\n",
    "        print(\"ㅎㅎ 아니야\")\n",
    "    elif number == 2:\n",
    "        print(\"ㅇㅋㅇㅋ\")\n",
    "    elif number == 3:\n",
    "        print(\"오케\")\n",
    "    elif number == 4:\n",
    "        print(\"오키\")\n",
    "    sys.exit()\n",
    "\n",
    "if ((\"메뉴\" in chat_input2) and (\"교\"in chat_input2)):\n",
    "    now = str(datetime.date.today())\n",
    "    url = \"https://www.ajou.ac.kr/kr/life/food.do?mode=view&articleNo=221&date=\"+\"2022-3-22\"+\"#menu\"\n",
    "    res = requests.get(url)\n",
    "    res.raise_for_status() \n",
    "    soup = BeautifulSoup(res.text,\"lxml\")\n",
    "    menu = soup.find_all(\"div\", attrs={\"class\":\"b-menu-box\"})\n",
    "\n",
    "    for k in menu:\n",
    "        k=k.text\n",
    "        k=k.replace(\"등록된 식단이 없습니다.\", \" \")\n",
    "        k=k.replace(\"\\n \", \" \")\n",
    "        k=k.replace(\"\\n\\n\", \" \")\n",
    "        k=k.replace(\"<석식-5,000원>\",\"\\n\\n<석식-5,000원>\")\n",
    "        k=k.replace(\"*식당 출입시 마스크 착용 부탁드립니다*\",\"\")\n",
    "        k=k.replace(\"(2학기 중 상시운영합니다.)\",\"\")\n",
    "        k=k.replace(\"    <중식-5,000원>\",\"<중식-5,000원>\")\n",
    "        \n",
    "        if(len(k)<10):\n",
    "            k = \"오늘은 교직원 식당 운영 안 해!\"\n",
    "        print(k)\n",
    "    sys.exit()\n",
    "    \n",
    "#코로나 확진자수\n",
    "if(((\"확진자\"in chat_input2) or(\"코로나\" in chat_input2)) and ((\"몇\" in chat_input2)or(\"수\" in chat_input2))):\n",
    "    url=\"https://search.naver.com/search.naver?sm=tab_hty.top&query=%EC%BD%94%EB%A1%9C%EB%82%98+%ED%99%95%EC%A7%84%EC%9E%90&oquery=%EC%BD%94%EB%A1%9C%EB%82%98+%ED%99%95%EC%A7%84%EC%9E%90\"\n",
    "    res = requests.get(url)\n",
    "    res.raise_for_status() \n",
    "    soup = BeautifulSoup(res.text,\"lxml\")\n",
    "    corona = soup.find(\"li\", attrs={\"class\":\"info_01\"}).text\n",
    "    print(\"{0}명이야!\".format(corona))\n",
    "    sys.exit()\n",
    "\n",
    "    \n",
    "#날씨   \n",
    "def is_cold(Temp):\n",
    "    if(Temp<5):\n",
    "        comment = \"추워! 따뜻하게 입어\"\n",
    "    elif(14<=Temp<20):\n",
    "        comment = \"따뜻해!\"\n",
    "    elif(20<=Temp):\n",
    "        comment = \"더워..\"\n",
    "    else: comment = \"적당해!\"\n",
    "    return comment\n",
    "     \n",
    "weather = [\"추워\",\"추우려\",\"더워\",\"더우려\",\"날씨\",\"춥\",\"덥\",\"추울\",\"더울\"]\n",
    "if any(format in chat_input2 for format in weather ): \n",
    "    url = \"https://search.naver.com/search.naver?sm=tab_hty.top&where=nexearch&query=%EB%82%A0%EC%94%A8&oquery=%EB%8B%A4%EC%9D%8C&tqi=hBWHOlp0YidssgeiVVsssssstMN-400420\"\n",
    "    res = requests.get(url)\n",
    "    res.raise_for_status() \n",
    "    soup = BeautifulSoup(res.text,\"lxml\")\n",
    "    \n",
    "    T = soup.find(\"div\",attrs={\"class\":\"temperature_text\"}).find(\"strong\").text\n",
    "    Real_Temp = T.replace(\"°\",\"\")\n",
    "    Real_Temp = int(Real_Temp.replace(\"현재 온도\",\"\"))\n",
    "    lowest = soup.find(\"span\",attrs={\"class\":\"lowest\"}).text\n",
    "    highest = soup.find(\"span\",attrs={\"class\":\"highest\"}).text\n",
    "    low = int(lowest[4:-1])\n",
    "    high = int(highest[4:-1])\n",
    "    \n",
    "    #현재온도\n",
    "    if(\"지금\"in chat_input2):\n",
    "        print(\"{0}로 {1}\".format(T,is_cold(Real_Temp)))\n",
    "    #현재X\n",
    "    else:\n",
    "        if(high-low>6):\n",
    "            comment1 = \"일교차가 크니 주의하고\"\n",
    "        else:\n",
    "            if(is_cold(high)==\"더워..\"):\n",
    "                comment1 = \"덥고\"\n",
    "            elif(is_cold(low)==\"추워! 따뜻하게 입어\"):\n",
    "                comment1 = \"춥고\"\n",
    "            else:\n",
    "                comment1 = \"적당하고\"\n",
    "        T = T.replace(\"현재 온도\",\"\")    \n",
    "        print(lowest+highest+\"로 \"+comment1+\" 지금은 {0}로 {1}\".format(T,is_cold(Real_Temp)))\n",
    "    sys.exit() \n",
    "\n",
    "\n",
    "    \n",
    "# 데이터 읽어오기 및 사전화 \n",
    "features = data['question'].tolist()\n",
    "corpus = [preprocessing.text.text_to_word_sequence(text) for text in features]\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "# 입력 채팅 전처리\n",
    "sent = []\n",
    "sent.append(chat_input2)\n",
    "chat_input = sent\n",
    "sequences2 = tokenizer.texts_to_sequences(chat_input)\n",
    "MAX_SEQ_LEN = 15\n",
    "padded_seqs = preprocessing.sequence.pad_sequences(sequences2, maxlen=MAX_SEQ_LEN, padding='post')\n",
    "\n",
    "\n",
    "predict = model.predict(padded_seqs)\n",
    "predict_class = tf.math.argmax(predict, axis=1)\n",
    "\n",
    "\n",
    "print(\"의도 예측 클래스 : \", predict_class.numpy())\n",
    "\n",
    "if predict_class.numpy() != 2:\n",
    "    number = random.randrange(1,4)\n",
    "    if number == 1:\n",
    "        print('무슨 말인지 모르겠어 ㅠㅠ')\n",
    "    elif number == 2:\n",
    "        print('이해못하겠어 ㅠㅠ')\n",
    "    elif number == 3:\n",
    "        print('이해 못해서 답을 못해주겠어 ㅠㅠ')\n",
    "    sys.exit()\n",
    "\n",
    "data2 = data.iloc[start:end+1]\n",
    "features = data2['question'].tolist()\n",
    "corpus = [preprocessing.text.text_to_word_sequence(text) for text in features]\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "sequences2 = tokenizer.texts_to_sequences(chat_input)\n",
    "padded_seqs = preprocessing.sequence.pad_sequences(sequences2, maxlen=MAX_SEQ_LEN, padding='post')\n",
    "\n",
    "predict2 = model2.predict(padded_seqs)\n",
    "predict_class2 = tf.math.argmax(predict2, axis=1)\n",
    "\n",
    "# print(\"의도 예측2 점수 : \", predict2)\n",
    "print(\"의도 예측2 클래스 : \", predict_class2.numpy())\n",
    "\n",
    "\n",
    "\n",
    "pos = p.pos(chat_input2)\n",
    "bow1 = []\n",
    "\n",
    "\n",
    "for i in range(len(pos)):\n",
    "    if (m.search(pos[i][1])) is not None: \n",
    "        bow1.append(pos[i][0])\n",
    "    elif o.search(pos[i][1]) is not None: \n",
    "        bow1.append(pos[i][0])    \n",
    "    elif n.search(pos[i][1]) is not None:\n",
    "        bow1.append(pos[i][0])\n",
    "\n",
    "print(bow1)\n",
    "r1 = 0 \n",
    "index=0\n",
    "bow2=[]\n",
    "bow=[]\n",
    "\n",
    "pcm = int(predict_class2.numpy())\n",
    "data3 = data2.groupby('label2').get_group(pcm).reset_index(drop=True)\n",
    "for i in range(len(data3['question'])):\n",
    "    bow2 = list(data3['N'][i].split()+data3['V'][i].split())\n",
    "    bow = bow1 + bow2 \n",
    "    word_dics = []\n",
    "    for token in bow:\n",
    "            if token not in word_dics:\n",
    "                word_dics.append(token)\n",
    "    freq_list1 = make_term_doc_mat(bow1, word_dics)\n",
    "    freq_list2 = make_term_doc_mat(bow2, word_dics)\n",
    "    doc1 = np.array(make_vector(freq_list1))\n",
    "    doc2 = np.array(make_vector(freq_list2))\n",
    "    r2 = cos_sim(doc1, doc2)\n",
    "    \n",
    "    if r2 > r1 :\n",
    "        r1 = r2\n",
    "        index = i\n",
    "        bow3 = bow2\n",
    "            \n",
    "#+data['X'][i].split()\n",
    "# 형태소 분석기를 이용해 단어 묶음 리스트 생성\n",
    "# for i in range(len(data['checked_question'])):\n",
    "#     if ((i>=start) & (i<= end)):\n",
    "#         bow2 = list(data['N'][i].split()+data['V'][i].split())\n",
    "#         bow = bow1 + bow2 \n",
    "#         word_dics = []\n",
    "#         for token in bow:\n",
    "#             if token not in word_dics:\n",
    "#                 word_dics.append(token)\n",
    "#         freq_list1 = make_term_doc_mat(bow1, word_dics)\n",
    "#         freq_list2 = make_term_doc_mat(bow2, word_dics)\n",
    "#         doc1 = np.array(make_vector(freq_list1))\n",
    "#         doc2 = np.array(make_vector(freq_list2))\n",
    "#         r2 = cos_sim(doc1, doc2)\n",
    "#         if r2 > r1 :\n",
    "#             r1 = r2\n",
    "#             index = i\n",
    "#             bow3 = bow\n",
    "print(bow3+bow1)\n",
    "# 단어 묶음 리스트를 하나로 합침\n",
    "if r1 < 0.45 :\n",
    "    print(\"다르게 말해 줄래? 잘 모르겠어 ㅠ\")\n",
    "    sys.exit()\n",
    "print(index,r1)\n",
    "print(data3['question'][index])\n",
    "print(data3['answer'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91547d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "383.844px",
    "left": "220px",
    "right": "20px",
    "top": "122px",
    "width": "613px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
